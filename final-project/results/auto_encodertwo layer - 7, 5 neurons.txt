logistic regression :
auc_score  = 0.6813
Accuracy  = 0.7727
F1 score  =  0.5455
Precision score  =  0.7
Recall score  =  0.4468
r2   =  -0.0718
confusion matrix   =  [[98  9]
 [26 21]]
mse   =  0.2273


*******
lda :
auc_score  = 0.6813
Accuracy  = 0.7727
F1 score  =  0.5455
Precision score  =  0.7
Recall score  =  0.4468
r2   =  -0.0718
confusion matrix   =  [[98  9]
 [26 21]]
mse   =  0.2273


*******
qda :
auc_score  = 0.666
Accuracy  = 0.7597
F1 score  =  0.5195
Precision score  =  0.6667
Recall score  =  0.4255
r2   =  -0.133
confusion matrix   =  [[97 10]
 [27 20]]
mse   =  0.2403


*******
gnb :
auc_score  = 0.5537
Accuracy  = 0.6948
F1 score  =  0.2769
Precision score  =  0.5
Recall score  =  0.1915
r2   =  -0.4393
confusion matrix   =  [[98  9]
 [38  9]]
mse   =  0.3052


*******
svm :
auc_score  = 0.6967
Accuracy  = 0.7857
F1 score  =  0.5714
Precision score  =  0.7333
Recall score  =  0.4681
r2   =  -0.0105
confusion matrix   =  [[99  8]
 [25 22]]
mse   =  0.2143


*******
random forrest :
auc_score  = 0.6772
Accuracy  = 0.7338
F1 score  =  0.5495
Precision score  =  0.5682
Recall score  =  0.5319
r2   =  -0.2555
confusion matrix   =  [[88 19]
 [22 25]]
mse   =  0.2662


*******
bagging :
auc_score  = 0.6818
Accuracy  = 0.7403
F1 score  =  0.5556
Precision score  =  0.5814
Recall score  =  0.5319
r2   =  -0.2249
confusion matrix   =  [[89 18]
 [22 25]]
mse   =  0.2597


*******
decision tree :
auc_score  = 0.6852
Accuracy  = 0.7532
F1 score  =  0.5581
Precision score  =  0.6154
Recall score  =  0.5106
r2   =  -0.1637
confusion matrix   =  [[92 15]
 [23 24]]
mse   =  0.2468


*******
