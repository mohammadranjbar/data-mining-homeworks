logistic regression :
auc_score  = 0.6959
Accuracy  = 0.7597
F1 score  =  0.5747
Precision score  =  0.625
Recall score  =  0.5319
r2   =  -0.133
confusion matrix   =  [[92 15]
 [22 25]]
mse   =  0.2403


*******
lda :
auc_score  = 0.6959
Accuracy  = 0.7597
F1 score  =  0.5747
Precision score  =  0.625
Recall score  =  0.5319
r2   =  -0.133
confusion matrix   =  [[92 15]
 [22 25]]
mse   =  0.2403


*******
qda :
auc_score  = 0.7133
Accuracy  = 0.7922
F1 score  =  0.6
Precision score  =  0.7273
Recall score  =  0.5106
r2   =  0.0201
confusion matrix   =  [[98  9]
 [23 24]]
mse   =  0.2078


*******
gnb :
auc_score  = 0.6375
Accuracy  = 0.7532
F1 score  =  0.4571
Precision score  =  0.6957
Recall score  =  0.3404
r2   =  -0.1637
confusion matrix   =  [[100   7]
 [ 31  16]]
mse   =  0.2468


*******
svm :
auc_score  = 0.7112
Accuracy  = 0.7727
F1 score  =  0.5977
Precision score  =  0.65
Recall score  =  0.5532
r2   =  -0.0718
confusion matrix   =  [[93 14]
 [21 26]]
mse   =  0.2273


*******
random forrest :
auc_score  = 0.6857
Accuracy  = 0.7208
F1 score  =  0.5657
Precision score  =  0.5385
Recall score  =  0.5957
r2   =  -0.3168
confusion matrix   =  [[83 24]
 [19 28]]
mse   =  0.2792


*******
bagging :
auc_score  = 0.6292
Accuracy  = 0.6753
F1 score  =  0.4898
Precision score  =  0.4706
Recall score  =  0.5106
r2   =  -0.5311
confusion matrix   =  [[80 27]
 [23 24]]
mse   =  0.3247


*******
decision tree :
auc_score  = 0.6351
Accuracy  = 0.6753
F1 score  =  0.5
Precision score  =  0.4717
Recall score  =  0.5319
r2   =  -0.5311
confusion matrix   =  [[79 28]
 [22 25]]
mse   =  0.3247


*******
