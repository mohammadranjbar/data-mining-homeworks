logistic regression :
auc_score  = 0.5003
Accuracy  = 0.3636
F1 score  =  0.4494
Precision score  =  0.3053
Recall score  =  0.8511
r2   =  -2.001
confusion matrix   =  [[16 91]
 [ 7 40]]
mse   =  0.6364


*******
lda :
auc_score  = 0.5045
Accuracy  = 0.4026
F1 score  =  0.439
Precision score  =  0.3077
Recall score  =  0.766
r2   =  -1.8173
confusion matrix   =  [[26 81]
 [11 36]]
mse   =  0.5974


*******
qda :
auc_score  = 0.5
Accuracy  = 0.6948
F1 score  =  0.0
Precision score  =  0.0
Recall score  =  0.0
r2   =  -0.4393
confusion matrix   =  [[107   0]
 [ 47   0]]
mse   =  0.3052


*******
gnb :
auc_score  = 0.5138
Accuracy  = 0.4156
F1 score  =  0.4444
Precision score  =  0.313
Recall score  =  0.766
r2   =  -1.756
confusion matrix   =  [[28 79]
 [11 36]]
mse   =  0.5844


*******
svm :
auc_score  = 0.4933
Accuracy  = 0.4286
F1 score  =  0.4133
Precision score  =  0.301
Recall score  =  0.6596
r2   =  -1.6948
confusion matrix   =  [[35 72]
 [16 31]]
mse   =  0.5714


*******
random forrest :
auc_score  = 0.5367
Accuracy  = 0.4805
F1 score  =  0.4444
Precision score  =  0.3299
Recall score  =  0.6809
r2   =  -1.4498
confusion matrix   =  [[42 65]
 [15 32]]
mse   =  0.5195


*******
bagging :
auc_score  = 0.5107
Accuracy  = 0.461
F1 score  =  0.4196
Precision score  =  0.3125
Recall score  =  0.6383
r2   =  -1.5417
confusion matrix   =  [[41 66]
 [17 30]]
mse   =  0.539


*******
decision tree :
auc_score  = 0.526
Accuracy  = 0.474
F1 score  =  0.4336
Precision score  =  0.3229
Recall score  =  0.6596
r2   =  -1.4804
confusion matrix   =  [[42 65]
 [16 31]]
mse   =  0.526


*******
