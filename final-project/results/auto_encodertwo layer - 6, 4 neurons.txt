logistic regression :
auc_score  = 0.7358
Accuracy  = 0.7987
F1 score  =  0.6353
Precision score  =  0.7105
Recall score  =  0.5745
r2   =  0.0507
confusion matrix   =  [[96 11]
 [20 27]]
mse   =  0.2013


*******
lda :
auc_score  = 0.7358
Accuracy  = 0.7987
F1 score  =  0.6353
Precision score  =  0.7105
Recall score  =  0.5745
r2   =  0.0507
confusion matrix   =  [[96 11]
 [20 27]]
mse   =  0.2013


*******
qda :
auc_score  = 0.5
Accuracy  = 0.6948
F1 score  =  0.0
Precision score  =  0.0
Recall score  =  0.0
r2   =  -0.4393
confusion matrix   =  [[107   0]
 [ 47   0]]
mse   =  0.3052


*******
gnb :
auc_score  = 0.5903
Accuracy  = 0.7208
F1 score  =  0.3582
Precision score  =  0.6
Recall score  =  0.2553
r2   =  -0.3168
confusion matrix   =  [[99  8]
 [35 12]]
mse   =  0.2792


*******
svm :
auc_score  = 0.7358
Accuracy  = 0.7987
F1 score  =  0.6353
Precision score  =  0.7105
Recall score  =  0.5745
r2   =  0.0507
confusion matrix   =  [[96 11]
 [20 27]]
mse   =  0.2013


*******
random forrest :
auc_score  = 0.6678
Accuracy  = 0.7208
F1 score  =  0.5376
Precision score  =  0.5435
Recall score  =  0.5319
r2   =  -0.3168
confusion matrix   =  [[86 21]
 [22 25]]
mse   =  0.2792


*******
bagging :
auc_score  = 0.6359
Accuracy  = 0.7013
F1 score  =  0.4889
Precision score  =  0.5116
Recall score  =  0.4681
r2   =  -0.4086
confusion matrix   =  [[86 21]
 [25 22]]
mse   =  0.2987


*******
decision tree :
auc_score  = 0.6904
Accuracy  = 0.7273
F1 score  =  0.5714
Precision score  =  0.549
Recall score  =  0.5957
r2   =  -0.2861
confusion matrix   =  [[84 23]
 [19 28]]
mse   =  0.2727


*******
