logistic regression :
auc_score  = 0.5975
Accuracy  = 0.7143
F1 score  =  0.3889
Precision score  =  0.56
Recall score  =  0.2979
r2   =  -0.3474
confusion matrix   =  [[96 11]
 [33 14]]
mse   =  0.2857


*******
lda :
auc_score  = 0.5975
Accuracy  = 0.7143
F1 score  =  0.3889
Precision score  =  0.56
Recall score  =  0.2979
r2   =  -0.3474
confusion matrix   =  [[96 11]
 [33 14]]
mse   =  0.2857


*******
qda :
auc_score  = 0.5742
Accuracy  = 0.6818
F1 score  =  0.3636
Precision score  =  0.4667
Recall score  =  0.2979
r2   =  -0.5005
confusion matrix   =  [[91 16]
 [33 14]]
mse   =  0.3182


*******
gnb :
auc_score  = 0.5405
Accuracy  = 0.7013
F1 score  =  0.2069
Precision score  =  0.5455
Recall score  =  0.1277
r2   =  -0.4086
confusion matrix   =  [[102   5]
 [ 41   6]]
mse   =  0.2987


*******
svm :
auc_score  = 0.5869
Accuracy  = 0.7078
F1 score  =  0.3662
Precision score  =  0.5417
Recall score  =  0.2766
r2   =  -0.378
confusion matrix   =  [[96 11]
 [34 13]]
mse   =  0.2922


*******
random forrest :
auc_score  = 0.6346
Accuracy  = 0.7078
F1 score  =  0.4828
Precision score  =  0.525
Recall score  =  0.4468
r2   =  -0.378
confusion matrix   =  [[88 19]
 [26 21]]
mse   =  0.2922


*******
bagging :
auc_score  = 0.7018
Accuracy  = 0.7597
F1 score  =  0.5843
Precision score  =  0.619
Recall score  =  0.5532
r2   =  -0.133
confusion matrix   =  [[91 16]
 [21 26]]
mse   =  0.2403


*******
decision tree :
auc_score  = 0.6639
Accuracy  = 0.7403
F1 score  =  0.5238
Precision score  =  0.5946
Recall score  =  0.4681
r2   =  -0.2249
confusion matrix   =  [[92 15]
 [25 22]]
mse   =  0.2597


*******
