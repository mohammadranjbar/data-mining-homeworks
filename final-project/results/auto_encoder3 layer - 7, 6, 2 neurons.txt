logistic regression :
auc_score  = 0.5
Accuracy  = 0.6948
F1 score  =  0.0
Precision score  =  0.0
Recall score  =  0.0
r2   =  -0.4393
confusion matrix   =  [[107   0]
 [ 47   0]]
mse   =  0.3052


*******
lda :
auc_score  = 0.5
Accuracy  = 0.6948
F1 score  =  0.0
Precision score  =  0.0
Recall score  =  0.0
r2   =  -0.4393
confusion matrix   =  [[107   0]
 [ 47   0]]
mse   =  0.3052


*******
qda :
auc_score  = 0.449
Accuracy  = 0.4416
F1 score  =  0.3385
Precision score  =  0.2651
Recall score  =  0.4681
r2   =  -1.6335
confusion matrix   =  [[46 61]
 [25 22]]
mse   =  0.5584


*******
gnb :
auc_score  = 0.4457
Accuracy  = 0.5779
F1 score  =  0.1333
Precision score  =  0.1786
Recall score  =  0.1064
r2   =  -0.9905
confusion matrix   =  [[84 23]
 [42  5]]
mse   =  0.4221


*******
svm :
auc_score  = 0.5
Accuracy  = 0.6948
F1 score  =  0.0
Precision score  =  0.0
Recall score  =  0.0
r2   =  -0.4393
confusion matrix   =  [[107   0]
 [ 47   0]]
mse   =  0.3052


*******
random forrest :
auc_score  = 0.4972
Accuracy  = 0.4091
F1 score  =  0.4277
Precision score  =  0.3036
Recall score  =  0.7234
r2   =  -1.7866
confusion matrix   =  [[29 78]
 [13 34]]
mse   =  0.5909


*******
bagging :
auc_score  = 0.4892
Accuracy  = 0.3896
F1 score  =  0.4268
Precision score  =  0.2991
Recall score  =  0.7447
r2   =  -1.8785
confusion matrix   =  [[25 82]
 [12 35]]
mse   =  0.6104


*******
decision tree :
auc_score  = 0.4726
Accuracy  = 0.3831
F1 score  =  0.4099
Precision score  =  0.2895
Recall score  =  0.7021
r2   =  -1.9091
confusion matrix   =  [[26 81]
 [14 33]]
mse   =  0.6169


*******
