logistic regression :
auc_score  = 0.6315
Accuracy  = 0.7532
F1 score  =  0.4412
Precision score  =  0.7143
Recall score  =  0.3191
r2   =  -0.1637
confusion matrix   =  [[101   6]
 [ 32  15]]
mse   =  0.2468


*******
lda :
auc_score  = 0.6222
Accuracy  = 0.7403
F1 score  =  0.4286
Precision score  =  0.6522
Recall score  =  0.3191
r2   =  -0.2249
confusion matrix   =  [[99  8]
 [32 15]]
mse   =  0.2597


*******
qda :
auc_score  = 0.6328
Accuracy  = 0.7468
F1 score  =  0.4507
Precision score  =  0.6667
Recall score  =  0.3404
r2   =  -0.1943
confusion matrix   =  [[99  8]
 [31 16]]
mse   =  0.2532


*******
gnb :
auc_score  = 0.6128
Accuracy  = 0.7273
F1 score  =  0.4167
Precision score  =  0.6
Recall score  =  0.3191
r2   =  -0.2861
confusion matrix   =  [[97 10]
 [32 15]]
mse   =  0.2727


*******
svm :
auc_score  = 0.6103
Accuracy  = 0.7403
F1 score  =  0.3939
Precision score  =  0.6842
Recall score  =  0.2766
r2   =  -0.2249
confusion matrix   =  [[101   6]
 [ 34  13]]
mse   =  0.2597


*******
random forrest :
auc_score  = 0.5432
Accuracy  = 0.5974
F1 score  =  0.38
Precision score  =  0.3585
Recall score  =  0.4043
r2   =  -0.8986
confusion matrix   =  [[73 34]
 [28 19]]
mse   =  0.4026


*******
bagging :
auc_score  = 0.536
Accuracy  = 0.6039
F1 score  =  0.3579
Precision score  =  0.3542
Recall score  =  0.3617
r2   =  -0.868
confusion matrix   =  [[76 31]
 [30 17]]
mse   =  0.3961


*******
decision tree :
auc_score  = 0.5466
Accuracy  = 0.6104
F1 score  =  0.375
Precision score  =  0.3673
Recall score  =  0.383
r2   =  -0.8373
confusion matrix   =  [[76 31]
 [29 18]]
mse   =  0.3896


*******
