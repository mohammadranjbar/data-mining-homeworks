logistic regression :
auc_score  = 0.515
Accuracy  = 0.6494
F1 score  =  0.2286
Precision score  =  0.3478
Recall score  =  0.1702
r2   =  -0.6536
confusion matrix   =  [[92 15]
 [39  8]]
mse   =  0.3506


*******
lda :
auc_score  = 0.521
Accuracy  = 0.6494
F1 score  =  0.25
Precision score  =  0.36
Recall score  =  0.1915
r2   =  -0.6536
confusion matrix   =  [[91 16]
 [38  9]]
mse   =  0.3506


*******
qda :
auc_score  = 0.5
Accuracy  = 0.6948
F1 score  =  0.0
Precision score  =  0.0
Recall score  =  0.0
r2   =  -0.4393
confusion matrix   =  [[107   0]
 [ 47   0]]
mse   =  0.3052


*******
gnb :
auc_score  = 0.5129
Accuracy  = 0.6299
F1 score  =  0.2597
Precision score  =  0.3333
Recall score  =  0.2128
r2   =  -0.7455
confusion matrix   =  [[87 20]
 [37 10]]
mse   =  0.3701


*******
svm :
auc_score  = 0.5
Accuracy  = 0.6948
F1 score  =  0.0
Precision score  =  0.0
Recall score  =  0.0
r2   =  -0.4393
confusion matrix   =  [[107   0]
 [ 47   0]]
mse   =  0.3052


*******
random forrest :
auc_score  = 0.5777
Accuracy  = 0.6039
F1 score  =  0.4404
Precision score  =  0.3871
Recall score  =  0.5106
r2   =  -0.868
confusion matrix   =  [[69 38]
 [23 24]]
mse   =  0.3961


*******
bagging :
auc_score  = 0.6011
Accuracy  = 0.6364
F1 score  =  0.4615
Precision score  =  0.4211
Recall score  =  0.5106
r2   =  -0.7149
confusion matrix   =  [[74 33]
 [23 24]]
mse   =  0.3636


*******
decision tree :
auc_score  = 0.4909
Accuracy  = 0.5909
F1 score  =  0.2588
Precision score  =  0.2895
Recall score  =  0.234
r2   =  -0.9292
confusion matrix   =  [[80 27]
 [36 11]]
mse   =  0.4091


*******
